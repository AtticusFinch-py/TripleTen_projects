{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "b1ab442d",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "\n",
    "#### Project Introduction: Subscriber Behavior Analysis for Mobile Plan Recommendation\n",
    "\n",
    "**Context:**  \n",
    "Mobile carrier Megaline has identified a significant portion of their customer base using outdated service plans. In response, they aim to encourage a transition to their modern plans - Smart or Ultra. To facilitate this, Megaline seeks to leverage data-driven strategies to understand subscriber behavior and guide them towards the most suitable plan.\n",
    "\n",
    "**Objective:**  \n",
    "The primary goal of this project is to develop a predictive model capable of analyzing subscriber behavior and accurately recommending one of Megaline's newer plans. The model will classify users into either the Smart or Ultra plan based on their usage patterns.\n",
    "\n",
    "**Data Overview:**  \n",
    "The dataset at our disposal (`users_behavior.csv`) contains detailed monthly behavior information of subscribers who have already shifted to the new plans. Key data points include:\n",
    "- `calls`: Number of calls made.\n",
    "- `minutes`: Total duration of calls.\n",
    "- `messages`: Number of text messages sent.\n",
    "- `mb_used`: Internet data consumption in MB.\n",
    "- `is_ultra`: Current plan of the user (Ultra - 1, Smart - 0).\n",
    "\n",
    "**Methodology:**  \n",
    "- **Data Preparation**: The data will be split into training, validation, and test sets to evaluate the model's performance effectively.\n",
    "- **Model Development**: We will explore various machine learning models, tweaking hyperparameters to optimize performance. The target is to achieve an accuracy score above 0.75.\n",
    "- **Model Evaluation**: Post-development, the model's accuracy will be validated using the test dataset.\n",
    "- **Additional Analysis**: A sanity check will be conducted to ensure the model's reliability, considering the complexity of the data.\n",
    "\n",
    "**Project Significance:**  \n",
    "This project demonstrates the application of machine learning in customer behavior analysis and decision support systems. By achieving the set accuracy threshold, the model will enable Megaline to enhance their service offerings, aligning them more closely with user preferences and behaviors.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "080a3059",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a48d50b6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load and view data\n",
    "df = pd.read_csv(\"/datasets/users_behavior.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d15b3eea",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    2229\n",
       "1     985\n",
       "Name: is_ultra, dtype: int64"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total_count = df['is_ultra'].value_counts()\n",
    "total_count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c9889599",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1928, 4)\n",
      "(1928,)\n",
      "(643, 4)\n",
      "(643,)\n",
      "(643, 4)\n",
      "(643,)\n"
     ]
    }
   ],
   "source": [
    "# Step 2: Split the source data into a training set, a validation set, and a test set.\n",
    "\n",
    "df_train, df_valid_and_test = train_test_split(df, test_size=0.4, random_state=42)\n",
    "df_valid, df_test = train_test_split(df_valid_and_test, test_size=0.5, random_state=42)\n",
    "\n",
    "features_train = df_train.drop(['is_ultra'], axis=1)\n",
    "target_train = df_train['is_ultra']\n",
    "\n",
    "features_valid = df_valid.drop(['is_ultra'], axis=1)\n",
    "target_valid = df_valid['is_ultra']\n",
    "\n",
    "features_test = df_test.drop(['is_ultra'], axis=1)\n",
    "target_test = df_test['is_ultra']\n",
    "\n",
    "print(features_train.shape)\n",
    "print(target_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(target_valid.shape)\n",
    "print(features_test.shape)\n",
    "print(target_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef4f3e2c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The data was split into train, validation and test sets. The proportions are reasonable\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d2beed5",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "<h2> Student's comment</h2>\n",
    "    \n",
    "The reason for splitting the dataset into training, validation, and test sets is to evaluate and compare the performance of machine learning models accurately. The training set is used to train the models, the validation set is used for hyperparameter tuning and model selection, and the test set is used for the final evaluation of the chosen model's performance. By using separate sets, we can assess how well the model generalizes to unseen data.\n",
    "    \n",
    "Looking at the shape of the data means examining the dimensions or structure of the dataset. In the given code, the shape refers to the number of rows and columns in each set of features and target variables. By printing the shapes of the data, we can understand how many samples (rows) and features (columns) are present in each set. It helps us gain insights into the size and structure of the data we are working with.    \n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ce56dc1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Good!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "39f12984",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>depth</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0.747925</td>\n",
       "      <td>0.730949</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>0.781639</td>\n",
       "      <td>0.782271</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>0.797199</td>\n",
       "      <td>0.791602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>0.808610</td>\n",
       "      <td>0.780715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0.815353</td>\n",
       "      <td>0.772939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>0.822614</td>\n",
       "      <td>0.776050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>0.838693</td>\n",
       "      <td>0.780715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>0.852178</td>\n",
       "      <td>0.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>0.863589</td>\n",
       "      <td>0.780715</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>0.878631</td>\n",
       "      <td>0.794712</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   depth  acc_train  acc_valid\n",
       "0      1   0.747925   0.730949\n",
       "1      2   0.781639   0.782271\n",
       "2      3   0.797199   0.791602\n",
       "3      4   0.808610   0.780715\n",
       "4      5   0.815353   0.772939\n",
       "5      6   0.822614   0.776050\n",
       "6      7   0.838693   0.780715\n",
       "7      8   0.852178   0.796267\n",
       "8      9   0.863589   0.780715\n",
       "9     10   0.878631   0.794712"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Step 3: Investigate the quality of different models by changing hyperparameters. \n",
    "# Briefly describe the findings of the study.\n",
    "# Decision Tree\n",
    "\n",
    "decision_tree_cols = ['depth', 'acc_train', 'acc_valid']\n",
    "decision_tree_list = []\n",
    "\n",
    "for depth in range(1, 11):\n",
    "    model_dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    model_dt.fit(features_train, target_train)\n",
    "    decision_tree_list.append([depth,\n",
    "                              model_dt.score(features_train, target_train),\n",
    "                              model_dt.score(features_valid, target_valid)\n",
    "                              ])\n",
    "    \n",
    "decision_tree = pd.DataFrame(decision_tree_list, columns=decision_tree_cols)\n",
    "decision_tree"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37b10aca",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "<h2> Student's comment</h2>\n",
    "\n",
    "The provided code investigates the impact of different maximum depths on the performance of Decision Tree models. It trains and evaluates Decision Tree models with depths ranging from 1 to 10. The findings reveal that increasing the depth initially enhances the accuracy of the training set, indicating better capturing of the training data's patterns. However, the accuracy of the validation set, which represents unseen data, reaches its peak at a depth of 3 and starts to decline after that. This suggests that deeper models overfit the training data, performing poorly on new, unseen data. In summary, the study demonstrates that while increasing the depth can improve the accuracy of the training set, more is needed to lead to better generalization of new data. The optimal depth for the Decision Tree model is 3, which balances training and validation accuracy, indicating good generalization performance.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b8adad90",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>estimator</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>10</td>\n",
       "      <td>0.980290</td>\n",
       "      <td>0.786936</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>20</td>\n",
       "      <td>0.991701</td>\n",
       "      <td>0.791602</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>30</td>\n",
       "      <td>0.994813</td>\n",
       "      <td>0.793157</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>40</td>\n",
       "      <td>0.997925</td>\n",
       "      <td>0.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>50</td>\n",
       "      <td>0.997925</td>\n",
       "      <td>0.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>60</td>\n",
       "      <td>0.999481</td>\n",
       "      <td>0.796267</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>70</td>\n",
       "      <td>0.998963</td>\n",
       "      <td>0.797823</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>80</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.800933</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>90</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802488</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>100</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.802488</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   estimator  acc_train  acc_valid\n",
       "0         10   0.980290   0.786936\n",
       "1         20   0.991701   0.791602\n",
       "2         30   0.994813   0.793157\n",
       "3         40   0.997925   0.796267\n",
       "4         50   0.997925   0.796267\n",
       "5         60   0.999481   0.796267\n",
       "6         70   0.998963   0.797823\n",
       "7         80   1.000000   0.800933\n",
       "8         90   1.000000   0.802488\n",
       "9        100   1.000000   0.802488"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest_cols = ['estimator', 'acc_train', 'acc_valid']\n",
    "random_forest_list = []\n",
    "\n",
    "for estimator in range(10, 101, 10):\n",
    "    model_rf = RandomForestClassifier(n_estimators=estimator, random_state=42)\n",
    "    model_rf.fit(features_train, target_train)\n",
    "    random_forest_list.append([estimator,\n",
    "                              model_rf.score(features_train, target_train),\n",
    "                              model_rf.score(features_valid, target_valid)\n",
    "                              ])\n",
    "    \n",
    "random_forest = pd.DataFrame(random_forest_list, columns=random_forest_cols)\n",
    "random_forest"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51f9ebba",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "    <h2> Student's comment</h2>\n",
    "\n",
    "The study investigates how increasing the number of estimators (trees) in a Random Forest model affects its performance. The findings reveal that as the number of estimators increases, the training and validation accuracies improve. However, there is a point where further increasing the number of estimators provides diminishing returns in terms of accuracy improvement.\n",
    "The accuracy of the training set improves as the number of estimators increases until it reaches the maximum value of 1 (or 100%). On the other hand, the validation accuracy stops improving after a certain number of estimators.\n",
    "Based on the results of this study, an optimal number of estimators lies between 80 and 90, as this range provides a reasonable balance between accuracy on the training and validation sets. Beyond this range, the additional estimators do not significantly improve the model's performance on unseen data, suggesting the presence of diminishing returns. In summary, increasing the number of estimators in a Random Forest initially enhances performance, but there is an optimal point where further increases do not provide significant benefits. Finding the appropriate number of estimators requires considering the dataset and balancing between model complexity and generalization ability.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "59f8b86c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_logistic.py:763: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
      "STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.\n",
      "\n",
      "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
      "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
      "Please also refer to the documentation for alternative solver options:\n",
      "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
      "  n_iter_i = _check_optimize_result(\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:456: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:415: LineSearchWarning: Rounding errors prevent the line search from converging\n",
      "  warn(msg, LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/scipy/optimize/_linesearch.py:305: LineSearchWarning: The line search algorithm did not converge\n",
      "  warn('The line search algorithm did not converge', LineSearchWarning)\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/utils/optimize.py:195: UserWarning: Line Search failed\n",
      "  warnings.warn('Line Search failed')\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n",
      "/opt/conda/lib/python3.9/site-packages/sklearn/linear_model/_sag.py:328: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
      "  warnings.warn(\"The max_iter was reached which means \"\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>solver</th>\n",
       "      <th>acc_train</th>\n",
       "      <th>acc_valid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>lbfgs</td>\n",
       "      <td>0.743257</td>\n",
       "      <td>0.740280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>liblinear</td>\n",
       "      <td>0.713693</td>\n",
       "      <td>0.720062</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>newton-cg</td>\n",
       "      <td>0.743257</td>\n",
       "      <td>0.740280</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>sag</td>\n",
       "      <td>0.693983</td>\n",
       "      <td>0.698289</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>saga</td>\n",
       "      <td>0.693465</td>\n",
       "      <td>0.695179</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "      solver  acc_train  acc_valid\n",
       "0      lbfgs   0.743257   0.740280\n",
       "1  liblinear   0.713693   0.720062\n",
       "2  newton-cg   0.743257   0.740280\n",
       "3        sag   0.693983   0.698289\n",
       "4       saga   0.693465   0.695179"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "solver_list = ['lbfgs', 'liblinear', 'newton-cg','sag', 'saga']\n",
    "logistic_regression_cols = ['solver', 'acc_train', 'acc_valid']\n",
    "logistic_regression_list = []\n",
    "\n",
    "for solver_item in solver_list:\n",
    "    model_lr = LogisticRegression(random_state=42, solver=solver_item)\n",
    "    model_lr.fit(features_train, target_train)\n",
    "    logistic_regression_list.append([solver_item,\n",
    "                              model_lr.score(features_train, target_train),\n",
    "                              model_lr.score(features_valid, target_valid)\n",
    "                              ])\n",
    "\n",
    "logistic_regression = pd.DataFrame(logistic_regression_list, columns=logistic_regression_cols)\n",
    "logistic_regression"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2ad4145",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "<h2> Student's comment</h2>\n",
    "\n",
    "Despite logistic regression's relatively lower accuracy, it compensates for it by being a fast algorithm. Among the available solvers, lbfgs and newton-cg demonstrate the highest accuracy on both the training and validation sets. Regrettably, none of the solvers achieve an accuracy above the desired threshold of 75%.\n",
    "    \n",
    "The random forest model achieves the highest accuracy but shows signs of overfitting. This is because it combines multiple decision trees into an ensemble, which helps improve prediction accuracy but can lead to overfitting issues.\n",
    "    \n",
    "The decision tree model comes in second place. If the tree depth is too shallow (below 2), the model needs to be more balanced and capture the complexity of the data. On the other hand, if the tree depth exceeds 3, the model tends to be overfitted, meaning it becomes too specific to the training data and may not generalize well to new data.\n",
    "    \n",
    "While having the lowest prediction quality and falling short of the desired threshold, logistic regression does not exhibit signs of overfitting. It may not capture the intricacies of the data as effectively as other models, but it avoids the problem of overfitting.    \n",
    "    \n",
    "</div>    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4a6280f9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Great, you tried a couple of different models and tuned their hyperparameters using the validation sets\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "2f111453",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of the model on the training set: 1.0\n",
      "Accuracy of the model on the validation set: 0.80248833592535\n",
      "Accuracy of the model on the test set: 0.8133748055987559\n"
     ]
    }
   ],
   "source": [
    "# Step4: Check the quality of the model using the test set.\n",
    "# Step 5: sanity check the model. \n",
    "# This data is more complex than what you’re used to working with, \n",
    "# so it's not an easy task. We'll take a closer look at it later.\n",
    "\n",
    "# Define and train the random forest classifier\n",
    "model = RandomForestClassifier(n_estimators=90, random_state=42)\n",
    "model.fit(features_train, target_train)\n",
    "\n",
    "# Calculate and print the accuracy of the model on different datasets\n",
    "train_accuracy = model.score(features_train, target_train)\n",
    "valid_accuracy = model.score(features_valid, target_valid)\n",
    "test_accuracy = model.score(features_test, target_test)\n",
    "\n",
    "# Display the accuracy results\n",
    "print('Accuracy of the model on the training set:', train_accuracy)\n",
    "print('Accuracy of the model on the validation set:', valid_accuracy)\n",
    "print('Accuracy of the model on the test set:', test_accuracy)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39d1e40c",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "<h2> Student's comment</h2>\n",
    "    \n",
    "The Random Forest model provides the accuracy of 81.33%.\n",
    "    \n",
    "</div>   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4895122",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The final model was evaluated on the test set for an unbiased estimate of its generalization performance\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a77daa24",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
