{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a7e00eea",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "\n",
    "#### Project Introduction: Predicting Customer Churn for Beta Bank\n",
    "\n",
    "**Project Background:**  \n",
    "Beta Bank is experiencing a steady loss of customers, and the management has recognized that retaining existing customers is more cost-effective than acquiring new ones. The challenge is to predict the likelihood of a customer leaving the bank, using data on clients' past behavior and contract termination history.\n",
    "\n",
    "**Objective:**  \n",
    "The aim is to build a predictive model that can accurately determine the probability of a customer leaving the bank. The primary metric for model performance is the F1 score, with a project requirement of achieving a minimum score of 0.59. Additionally, the model's AUC-ROC metric will also be evaluated to understand the trade-off between sensitivity and specificity.\n",
    "\n",
    "**Data Overview:**  \n",
    "The dataset (`Churn.csv`) provides comprehensive information on customers, including demographics, account details, and banking behavior. Key features include Credit Score, Geography, Gender, Age, Tenure, Account Balance, Number of Products, Credit Card Ownership, Customer Activity, and Estimated Salary.\n",
    "\n",
    "**Methodology:**\n",
    "\n",
    "1. **Data Preparation:**  \n",
    "   Detailed preprocessing of the data includes handling missing values, encoding categorical variables, and feature scaling. The preprocessing steps will be thoroughly explained.\n",
    "\n",
    "2. **Class Balance Analysis:**  \n",
    "   Investigate the balance of the target classes (customer churn). Initially, models will be trained without addressing class imbalance to establish a baseline.\n",
    "\n",
    "3. **Model Improvement:**  \n",
    "   Implement at least two techniques to manage class imbalance, such as resampling methods or adjusting class weights. Different models will be trained on the adjusted data, and their performance will be compared to select the best model.\n",
    "\n",
    "4. **Model Evaluation:**  \n",
    "   Conduct final testing to assess the chosen model's effectiveness, focusing on the F1 score and AUC-ROC metrics.\n",
    "\n",
    "**Significance:**  \n",
    "This project not only serves as an application of machine learning in solving a real-world business problem but also demonstrates proficiency in handling imbalanced datasets, a common challenge in predictive modeling. The outcome will assist Beta Bank in implementing strategies to improve customer retention.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "52cdaff9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "from sklearn.metrics import accuracy_score, f1_score, precision_score, recall_score, precision_recall_curve, roc_curve, roc_auc_score\n",
    "from sklearn.utils import shuffle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e2be1599",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>RowNumber</th>\n",
       "      <th>CustomerId</th>\n",
       "      <th>Surname</th>\n",
       "      <th>CreditScore</th>\n",
       "      <th>Geography</th>\n",
       "      <th>Gender</th>\n",
       "      <th>Age</th>\n",
       "      <th>Tenure</th>\n",
       "      <th>Balance</th>\n",
       "      <th>NumOfProducts</th>\n",
       "      <th>HasCrCard</th>\n",
       "      <th>IsActiveMember</th>\n",
       "      <th>EstimatedSalary</th>\n",
       "      <th>Exited</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>15634602</td>\n",
       "      <td>Hargrave</td>\n",
       "      <td>619</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>101348.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>15647311</td>\n",
       "      <td>Hill</td>\n",
       "      <td>608</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>41</td>\n",
       "      <td>1.0</td>\n",
       "      <td>83807.86</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>112542.58</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>15619304</td>\n",
       "      <td>Onio</td>\n",
       "      <td>502</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>42</td>\n",
       "      <td>8.0</td>\n",
       "      <td>159660.80</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113931.57</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>15701354</td>\n",
       "      <td>Boni</td>\n",
       "      <td>699</td>\n",
       "      <td>France</td>\n",
       "      <td>Female</td>\n",
       "      <td>39</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>93826.63</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>15737888</td>\n",
       "      <td>Mitchell</td>\n",
       "      <td>850</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Female</td>\n",
       "      <td>43</td>\n",
       "      <td>2.0</td>\n",
       "      <td>125510.82</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>79084.10</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>15574012</td>\n",
       "      <td>Chu</td>\n",
       "      <td>645</td>\n",
       "      <td>Spain</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>8.0</td>\n",
       "      <td>113755.78</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>149756.71</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>15592531</td>\n",
       "      <td>Bartlett</td>\n",
       "      <td>822</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>50</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>10062.80</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>15656148</td>\n",
       "      <td>Obinna</td>\n",
       "      <td>376</td>\n",
       "      <td>Germany</td>\n",
       "      <td>Female</td>\n",
       "      <td>29</td>\n",
       "      <td>4.0</td>\n",
       "      <td>115046.74</td>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>119346.88</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>15792365</td>\n",
       "      <td>He</td>\n",
       "      <td>501</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>44</td>\n",
       "      <td>4.0</td>\n",
       "      <td>142051.07</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>74940.50</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>15592389</td>\n",
       "      <td>H?</td>\n",
       "      <td>684</td>\n",
       "      <td>France</td>\n",
       "      <td>Male</td>\n",
       "      <td>27</td>\n",
       "      <td>2.0</td>\n",
       "      <td>134603.88</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>71725.73</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   RowNumber  CustomerId   Surname  CreditScore Geography  Gender  Age  \\\n",
       "0          1    15634602  Hargrave          619    France  Female   42   \n",
       "1          2    15647311      Hill          608     Spain  Female   41   \n",
       "2          3    15619304      Onio          502    France  Female   42   \n",
       "3          4    15701354      Boni          699    France  Female   39   \n",
       "4          5    15737888  Mitchell          850     Spain  Female   43   \n",
       "5          6    15574012       Chu          645     Spain    Male   44   \n",
       "6          7    15592531  Bartlett          822    France    Male   50   \n",
       "7          8    15656148    Obinna          376   Germany  Female   29   \n",
       "8          9    15792365        He          501    France    Male   44   \n",
       "9         10    15592389        H?          684    France    Male   27   \n",
       "\n",
       "   Tenure    Balance  NumOfProducts  HasCrCard  IsActiveMember  \\\n",
       "0     2.0       0.00              1          1               1   \n",
       "1     1.0   83807.86              1          0               1   \n",
       "2     8.0  159660.80              3          1               0   \n",
       "3     1.0       0.00              2          0               0   \n",
       "4     2.0  125510.82              1          1               1   \n",
       "5     8.0  113755.78              2          1               0   \n",
       "6     7.0       0.00              2          1               1   \n",
       "7     4.0  115046.74              4          1               0   \n",
       "8     4.0  142051.07              2          0               1   \n",
       "9     2.0  134603.88              1          1               1   \n",
       "\n",
       "   EstimatedSalary  Exited  \n",
       "0        101348.88       1  \n",
       "1        112542.58       0  \n",
       "2        113931.57       1  \n",
       "3         93826.63       0  \n",
       "4         79084.10       0  \n",
       "5        149756.71       1  \n",
       "6         10062.80       0  \n",
       "7        119346.88       1  \n",
       "8         74940.50       0  \n",
       "9         71725.73       0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 10000 entries, 0 to 9999\n",
      "Data columns (total 14 columns):\n",
      " #   Column           Non-Null Count  Dtype  \n",
      "---  ------           --------------  -----  \n",
      " 0   RowNumber        10000 non-null  int64  \n",
      " 1   CustomerId       10000 non-null  int64  \n",
      " 2   Surname          10000 non-null  object \n",
      " 3   CreditScore      10000 non-null  int64  \n",
      " 4   Geography        10000 non-null  object \n",
      " 5   Gender           10000 non-null  object \n",
      " 6   Age              10000 non-null  int64  \n",
      " 7   Tenure           9091 non-null   float64\n",
      " 8   Balance          10000 non-null  float64\n",
      " 9   NumOfProducts    10000 non-null  int64  \n",
      " 10  HasCrCard        10000 non-null  int64  \n",
      " 11  IsActiveMember   10000 non-null  int64  \n",
      " 12  EstimatedSalary  10000 non-null  float64\n",
      " 13  Exited           10000 non-null  int64  \n",
      "dtypes: float64(3), int64(8), object(3)\n",
      "memory usage: 1.1+ MB\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "None"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(10000, 14)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Download and prepare the data\n",
    "\n",
    "data = pd.read_csv('/datasets/Churn.csv')\n",
    "display(data.head(10))\n",
    "print('-'*40)\n",
    "display(data.info())\n",
    "print('-'*40)\n",
    "display(data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "79a6c15d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 11)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# remove unnecessary columns\n",
    "data = data.drop(['RowNumber', 'CustomerId', 'Surname'], axis=1)\n",
    "\n",
    "# drop rows with missing Tenure values\n",
    "data['Tenure'] = data['Tenure'].fillna(value=data['Tenure'].median())\n",
    "\n",
    "data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "609f6757",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Missing values were dealt with reasonably\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "7d2ab568",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6000, 11)\n",
      "(2000, 11)\n",
      "(2000, 11)\n"
     ]
    }
   ],
   "source": [
    "# Step2: Examine the balance of classes. Train the model without taking into account the imbalance. \n",
    "# Briefly describe your findings.\n",
    "\n",
    "# Perform categorical feature encoding \n",
    "data_ohe = pd.get_dummies(data, drop_first=True)\n",
    "target = data_ohe['Exited']\n",
    "features = data_ohe.drop('Exited', axis=1)\n",
    "\n",
    "# Perform splitting data\n",
    "features_train, features_valid_test, target_train, target_valid_test = train_test_split(features, \n",
    "                                                                                        target, \n",
    "                                                                                        test_size=0.4, \n",
    "                                                                                        random_state=42)\n",
    "\n",
    "features_valid, features_test, target_valid, target_test = train_test_split(features_valid_test, \n",
    "                                                                            target_valid_test, \n",
    "                                                                            test_size=0.5,\n",
    "                                                                            random_state=42)\n",
    "\n",
    "# print the shape of each feature\n",
    "print(features_train.shape)\n",
    "print(features_valid.shape)\n",
    "print(features_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9edfe8f1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Categorical features were encoded, the data was split into train, validation and test sets\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e7cff75a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solver         lbfgs\n",
       "acc            0.801\n",
       "f1_score    0.111607\n",
       "Name: 0, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Logistic Regression\n",
    "\n",
    "solver_list = ['lbfgs', 'liblinear']\n",
    "logistic_regression_cols = ['solver', 'acc', 'f1_score']\n",
    "logistic_regression_list = []\n",
    "\n",
    "for solver_item in solver_list:\n",
    "    model_lr = LogisticRegression(random_state=42, solver=solver_item)\n",
    "    model_lr.fit(features_train, target_train)\n",
    "    predicted_valid = model_lr.predict(features_valid)\n",
    "    logistic_regression_list.append([solver_item,\n",
    "                              accuracy_score(target_valid, predicted_valid),\n",
    "                              f1_score(target_valid, predicted_valid)\n",
    "                              ])\n",
    "\n",
    "logistic_regression = pd.DataFrame(logistic_regression_list, columns=logistic_regression_cols)\n",
    "max_f1_score_row = logistic_regression.loc[logistic_regression['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f0cf81bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solver          liblinear\n",
       "class_weight     balanced\n",
       "f1_score         0.458794\n",
       "Name: 2, dtype: object"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class Weight adjustment\n",
    "\n",
    "logistic_regression_cols = ['solver', 'class_weight', 'f1_score']\n",
    "logistic_regression_list = []\n",
    "\n",
    "for solver_item in solver_list:\n",
    "    for class_weight in ['balanced', None]:\n",
    "        model_lr = LogisticRegression(random_state=42, solver=solver_item, class_weight=class_weight)\n",
    "        model_lr.fit(features_train, target_train)\n",
    "        predicted_valid = model_lr.predict(features_valid)\n",
    "        logistic_regression_list.append([solver_item,\n",
    "                                   class_weight,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "logistic_regression = pd.DataFrame(logistic_regression_list, columns=logistic_regression_cols)\n",
    "\n",
    "max_f1_score_row = logistic_regression.loc[logistic_regression['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4d25f968",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Class weights were applied successfully\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "21e728b0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4773, 11)\n",
      "(1227, 11)\n",
      "(4773,)\n",
      "(1227,)\n"
     ]
    }
   ],
   "source": [
    "# Upsampling\n",
    "\n",
    "features_zeros = features_train[target_train == 0]\n",
    "features_ones = features_train[target_train == 1]\n",
    "target_zeros = target_train[target_train == 0]\n",
    "target_ones = target_train[target_train == 1]\n",
    "\n",
    "print(features_zeros.shape)\n",
    "print(features_ones.shape)\n",
    "print(target_zeros.shape)\n",
    "print(target_ones.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "3bd64b86",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solver         lbfgs\n",
       "repeat             4\n",
       "f1_score    0.399038\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logistic_regression_cols = ['solver', 'repeat', 'f1_score']\n",
    "logistic_regression_list = []\n",
    "\n",
    "for solver_item in solver_list:\n",
    "    for repeat in range(1, 5):\n",
    "        features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "        target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "        features_upsampled, target_upsampled = shuffle(features_upsampled,\n",
    "                                                       target_upsampled, \n",
    "                                                       random_state=42)\n",
    "        model_lr = LogisticRegression(random_state=42, solver=solver_item)\n",
    "        model_lr.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = model_lr.predict(features_valid)\n",
    "        logistic_regression_list.append([solver_item,\n",
    "                                   repeat,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "        \n",
    "logistic_regression = pd.DataFrame(logistic_regression_list, columns=logistic_regression_cols)\n",
    "\n",
    "max_f1_score_row = logistic_regression.loc[logistic_regression['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d56ef79",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Upsampling was correctly applied only to the train set\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "9b75ffbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solver         lbfgs\n",
       "fraction        0.25\n",
       "f1_score    0.399361\n",
       "Name: 3, dtype: object"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsampling\n",
    "\n",
    "logistic_regression_cols = ['solver', 'fraction', 'f1_score']\n",
    "logistic_regression_list = []\n",
    "\n",
    "for solver_item in solver_list:\n",
    "    for fraction in  np.arange(0.1, 1, 0.05):\n",
    "        features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=42)] + [features_ones])\n",
    "        target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=42)] + [target_ones])\n",
    "        features_downsampled, target_downsampled = shuffle(features_downsampled, \n",
    "                                                           target_downsampled, \n",
    "                                                           random_state=42)\n",
    "        model_lr = LogisticRegression(random_state=42, solver=solver_item)\n",
    "        model_lr.fit(features_downsampled, target_downsampled)\n",
    "        predicted_valid = model_lr.predict(features_valid)\n",
    "        logistic_regression_list.append([solver_item,\n",
    "                                         fraction,\n",
    "                                         f1_score(target_valid, predicted_valid)\n",
    "                                        ])\n",
    "        \n",
    "logistic_regression = pd.DataFrame(logistic_regression_list, columns=logistic_regression_cols)\n",
    "\n",
    "max_f1_score_row = logistic_regression.loc[logistic_regression['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3f00814c",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Downsampling was applied only to the train set\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "f7b206c5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "solver         lbfgs\n",
       "threshold        0.2\n",
       "f1_score     0.36654\n",
       "Name: 4, dtype: object"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold Adjustment\n",
    "\n",
    "logistic_regression_cols = ['solver', 'threshold', 'f1_score']\n",
    "logistic_regression_list = []\n",
    "\n",
    "for solver_item in solver_list:\n",
    "    for threshold in  np.arange(0, 1, 0.05):\n",
    "        model_lr = LogisticRegression(random_state=42, solver=solver_item)\n",
    "        model_lr.fit(features_train, target_train)\n",
    "        probabilities_valid = model_lr.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        predicted_valid = probabilities_one_valid > threshold\n",
    "        logistic_regression_list.append([solver_item,\n",
    "                                   threshold,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "        \n",
    "logistic_regression = pd.DataFrame(logistic_regression_list, columns=logistic_regression_cols)\n",
    "\n",
    "max_f1_score_row = logistic_regression.loc[logistic_regression['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a1d1f3e",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "<h2> Student's comment</h2>\n",
    "\n",
    "After exploring multiple methods to enhance the performance of our logistic regression model, including adjusting hyperparameters and addressing class imbalance, we were unable to attain our desired F1 score threshold. Despite attempting various techniques such as solver adjustment, class weights, upsampling/downsampling, and threshold tuning, none of these methods could achieve an F1 score of 0.59 or higher.\n",
    "Considering the limited success of individual adjustments, combining them is unlikely to yield a significant improvement. Therefore, we need to explore alternative models that may better address the class imbalance issue and potentially produce superior results. Our next step involves constructing a decision tree model and evaluating its performance in addressing the challenges faced.\n",
    "    \n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72212ea5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Very good!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "87b3aee1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth       6.000000\n",
       "acc         0.854000\n",
       "f1_score    0.522876\n",
       "Name: 5, dtype: float64"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Decision Tree\n",
    "\n",
    "decision_tree_cols = ['depth', 'acc', 'f1_score']\n",
    "decision_tree_list = []\n",
    "\n",
    "for depth in range(1, 12):\n",
    "    model_dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "    model_dt.fit(features_train, target_train)\n",
    "    predicted_valid = model_dt.predict(features_valid)\n",
    "    decision_tree_list.append([depth,\n",
    "                               accuracy_score(target_valid, predicted_valid),\n",
    "                               f1_score(target_valid, predicted_valid)\n",
    "                              ])\n",
    "    \n",
    "decision_tree = pd.DataFrame(decision_tree_list, columns=decision_tree_cols)\n",
    "\n",
    "max_f1_score_row = decision_tree.loc[decision_tree['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "51ffe118",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth                  7\n",
       "class_weight    balanced\n",
       "f1_score        0.552339\n",
       "Name: 12, dtype: object"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class Weight adjustment\n",
    "\n",
    "decision_tree_cols = ['depth','class_weight','f1_score']\n",
    "decision_tree_list = []\n",
    "\n",
    "for depth in range(1, 12):\n",
    "    for class_weight in ['balanced', None]:\n",
    "        model_dt = DecisionTreeClassifier(max_depth=depth, class_weight=class_weight,  random_state=42)\n",
    "        model_dt.fit(features_train, target_train)\n",
    "        predicted_valid = model_dt.predict(features_valid)\n",
    "        decision_tree_list.append([depth,\n",
    "                                   class_weight,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "decision_tree = pd.DataFrame(decision_tree_list, columns=decision_tree_cols)\n",
    "\n",
    "max_f1_score_row = decision_tree.loc[decision_tree['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "a01b16d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth       7.000000\n",
       "repeat      2.000000\n",
       "f1_score    0.554945\n",
       "Name: 25, dtype: float64"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsampling\n",
    "\n",
    "decision_tree_cols = ['depth','repeat','f1_score']\n",
    "decision_tree_list = []\n",
    "\n",
    "for depth in range(1,12):\n",
    "    for repeat in range(1, 5):\n",
    "        features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "        target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "        features_upsampled, target_upsampled = shuffle(features_upsampled,\n",
    "                                                       target_upsampled, \n",
    "                                                       random_state=42)\n",
    "        model_dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "        model_dt.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = model_dt.predict(features_valid)\n",
    "        decision_tree_list.append([depth,\n",
    "                                   repeat,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "decision_tree = pd.DataFrame(decision_tree_list, columns=decision_tree_cols)\n",
    "\n",
    "max_f1_score_row = decision_tree.loc[decision_tree['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4b83ebfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth       7.000000\n",
       "fraction    0.600000\n",
       "f1_score    0.576271\n",
       "Name: 132, dtype: float64"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsampling\n",
    "\n",
    "decision_tree_cols = ['depth','fraction','f1_score']\n",
    "decision_tree_list = []\n",
    "\n",
    "for depth in range(1,12):\n",
    "    for fraction in  np.arange(0, 1, 0.05):\n",
    "        features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=42)] + [features_ones])\n",
    "        target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=42)] + [target_ones])\n",
    "        features_downsampled, target_downsampled = shuffle(features_downsampled, \n",
    "                                                           target_downsampled, \n",
    "                                                           random_state=42)\n",
    "        model_dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "        model_dt.fit(features_downsampled, target_downsampled)\n",
    "        predicted_valid = model_dt.predict(features_valid)\n",
    "        decision_tree_list.append([depth,\n",
    "                                   fraction,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "decision_tree = pd.DataFrame(decision_tree_list, columns=decision_tree_cols)\n",
    "\n",
    "max_f1_score_row = decision_tree.loc[decision_tree['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "6df1703e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth        5.000000\n",
       "threshold    0.300000\n",
       "f1_score     0.553672\n",
       "Name: 86, dtype: float64"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold Adjustment\n",
    "\n",
    "decision_tree_cols = ['depth','threshold','f1_score']\n",
    "decision_tree_list = []\n",
    "\n",
    "for depth in range(1,12):\n",
    "    for threshold in  np.arange(0, 1, 0.05):\n",
    "        model_dt = DecisionTreeClassifier(max_depth=depth, random_state=42)\n",
    "        model_dt.fit(features_train, target_train)\n",
    "        probabilities_valid = model_dt.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        predicted_valid = probabilities_one_valid > threshold\n",
    "        decision_tree_list.append([depth,\n",
    "                                   threshold,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "decision_tree = pd.DataFrame(decision_tree_list, columns=decision_tree_cols)\n",
    "\n",
    "max_f1_score_row = decision_tree.loc[decision_tree['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fbc34a6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "depth                  7\n",
       "class_weight        None\n",
       "fraction             0.6\n",
       "threshold            0.5\n",
       "f1_score        0.576271\n",
       "Name: 1365, dtype: object"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Combining adjustments\n",
    "\n",
    "decision_tree_cols = ['depth','class_weight','fraction','threshold','f1_score']\n",
    "decision_tree_list = []\n",
    "\n",
    "for depth in range(1, 12):\n",
    "    for class_weight in ['balanced', None]:\n",
    "        for fraction in  np.arange(0, 1, 0.1):\n",
    "            for threshold in  np.arange(0, 1, 0.1):\n",
    "                features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=42)] + [features_ones])\n",
    "                target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=42)] + [target_ones])\n",
    "                features_downsampled, target_downsampled = shuffle(features_downsampled, \n",
    "                                                                   target_downsampled, \n",
    "                                                                   random_state=42)\n",
    "                model_dt = DecisionTreeClassifier(max_depth=depth, class_weight=class_weight, random_state=42)\n",
    "                model_dt.fit(features_downsampled, target_downsampled)\n",
    "                probabilities_valid = model_dt.predict_proba(features_valid)\n",
    "                if probabilities_valid.shape[1] == 1:\n",
    "                    probabilities_one_valid = probabilities_valid.ravel()\n",
    "                else:\n",
    "                    probabilities_one_valid = probabilities_valid[:, 1]\n",
    "                predicted_valid = probabilities_one_valid > threshold\n",
    "\n",
    "                decision_tree_list.append([depth,\n",
    "                                           class_weight,\n",
    "                                           fraction,\n",
    "                                           threshold,\n",
    "                                           f1_score(target_valid, predicted_valid)\n",
    "                                          ])\n",
    "\n",
    "decision_tree = pd.DataFrame(decision_tree_list, columns=decision_tree_cols)\n",
    "\n",
    "max_f1_score_row = decision_tree.loc[decision_tree['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7b3130",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "\n",
    "#### Project Introduction: Predicting Customer Churn for Beta Bank\n",
    "\n",
    "**Project Background:**  \n",
    "Beta Bank is experiencing a steady loss of customers, and the management has recognized that retaining existing customers is more cost-effective than acquiring new ones. The challenge is to predict the likelihood of a customer leaving the bank, using data on clients' past behavior and contract termination history.\n",
    "\n",
    "**Objective:**  \n",
    "The aim is to build a predictive model that can accurately determine the probability of a customer leaving the bank. The primary metric for model performance is the F1 score, with a project requirement of achieving a minimum score of 0.59. Additionally, the model's AUC-ROC metric will also be evaluated to understand the trade-off between sensitivity and specificity.\n",
    "\n",
    "**Data Overview:**  \n",
    "The dataset (`Churn.csv`) provides comprehensive information on customers, including demographics, account details, and banking behavior. Key features include Credit Score, Geography, Gender, Age, Tenure, Account Balance, Number of Products, Credit Card Ownership, Customer Activity, and Estimated Salary.\n",
    "\n",
    "**Methodology:**\n",
    "\n",
    "1. **Data Preparation:**  \n",
    "   Detailed preprocessing of the data includes handling missing values, encoding categorical variables, and feature scaling. The preprocessing steps will be thoroughly explained.\n",
    "\n",
    "2. **Class Balance Analysis:**  \n",
    "   Investigate the balance of the target classes (customer churn). Initially, models will be trained without addressing class imbalance to establish a baseline.\n",
    "\n",
    "3. **Model Improvement:**  \n",
    "   Implement at least two techniques to manage class imbalance, such as resampling methods or adjusting class weights. Different models will be trained on the adjusted data, and their performance will be compared to select the best model.\n",
    "\n",
    "4. **Model Evaluation:**  \n",
    "   Conduct final testing to assess the chosen model's effectiveness, focusing on the F1 score and AUC-ROC metrics.\n",
    "\n",
    "**Significance:**  \n",
    "This project not only serves as an application of machine learning in solving a real-world business problem but also demonstrates proficiency in handling imbalanced datasets, a common challenge in predictive modeling. The outcome will assist Beta Bank in implementing strategies to improve customer retention.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c322101",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "\n",
    "<h2> Improved Student's Comment on Hyperparameter Tuning in Decision Tree Model</h2>\n",
    "\n",
    "The code implements a comprehensive hyperparameter tuning strategy for a decision tree model, aimed at optimizing the F1 score. It employs a nested loop to systematically iterate through a range of hyperparameters, including depth, class_weight, fraction, and threshold.\n",
    "\n",
    "**Key Steps in the Process:**\n",
    "\n",
    "1. **Downsampling and Data Preparation:**  \n",
    "   The code creates a balanced dataset by downsampling the majority class. This involves merging a specified fraction of the majority class samples with all samples from the minority class. The combined dataset is shuffled for randomness.\n",
    "\n",
    "2. **Model Initialization and Training:**  \n",
    "   A decision tree classifier is set up with varying `max_depth` (from 1 to 11) and `class_weight` (either 'balanced' or None). The model is then trained on the prepared dataset.\n",
    "\n",
    "3. **Probability Prediction and Threshold Application:**  \n",
    "   The model predicts probabilities for the validation set. Depending on the output format, the relevant probabilities (either flattened or for the positive class) are extracted. These probabilities are then subjected to a defined threshold to classify observations.\n",
    "\n",
    "4. **F1 Score Calculation:**  \n",
    "   The model's performance is evaluated by calculating the F1 score, comparing the predicted labels against the actual labels in the validation set.\n",
    "\n",
    "5. **Hyperparameter and Performance Logging:**  \n",
    "   Each iteration logs the hyperparameters and the achieved F1 score. This data is stored in a structured format for further analysis.\n",
    "\n",
    "6. **Optimal Hyperparameters Identification:**  \n",
    "   After completing the iterations, the combination yielding the highest F1 score is identified. This optimal set of hyperparameters represents the most effective configuration for the decision tree model under the given conditions.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "This methodical approach to hyperparameter tuning provides a detailed understanding of the decision tree model's performance across different settings. The process ensures the identification of the most effective model configuration, balancing the trade-offs between precision and recall as reflected in the F1 score.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e3bdfe85",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Great, you tried a different model, applied all the same balancing techniques to it and tuned hyperparameters using the validation set\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4dabf6ff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimator    80.000000\n",
       "acc           0.865000\n",
       "f1_score      0.557377\n",
       "Name: 7, dtype: float64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random Forest\n",
    "\n",
    "random_forest_cols = ['estimator', 'acc', 'f1_score']\n",
    "random_forest_list = []\n",
    "\n",
    "for estimator in range(10, 101, 10):\n",
    "    model_rf = RandomForestClassifier(n_estimators=estimator, random_state=42)\n",
    "    model_rf.fit(features_train, target_train)\n",
    "    predicted_valid = model_rf.predict(features_valid)\n",
    "    random_forest_list.append([estimator,\n",
    "                               accuracy_score(target_valid, predicted_valid),\n",
    "                               f1_score(target_valid, predicted_valid)\n",
    "                              ])\n",
    "    \n",
    "random_forest = pd.DataFrame(random_forest_list, columns=random_forest_cols)\n",
    "\n",
    "max_f1_score_row = random_forest.loc[random_forest['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "b529a525",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimator             80\n",
       "class_weight        None\n",
       "f1_score        0.557377\n",
       "Name: 15, dtype: object"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Class Weight Adjustment\n",
    "\n",
    "random_forest_cols = ['estimator','class_weight','f1_score']\n",
    "random_forest_list = []\n",
    "\n",
    "for estimator in range(10, 101, 10):\n",
    "    for class_weight in ['balanced', None]:\n",
    "        model_rf = RandomForestClassifier(n_estimators=estimator, class_weight=class_weight,  random_state=42)\n",
    "        model_rf.fit(features_train, target_train)\n",
    "        predicted_valid = model_rf.predict(features_valid)\n",
    "        random_forest_list.append([estimator,\n",
    "                                   class_weight,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "random_forest = pd.DataFrame(random_forest_list, columns=random_forest_cols)\n",
    "\n",
    "max_f1_score_row = random_forest.loc[random_forest['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "0812d43a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimator    120.000000\n",
       "repeat         2.000000\n",
       "f1_score       0.583704\n",
       "Name: 45, dtype: float64"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Upsampling\n",
    "\n",
    "random_forest_cols = ['estimator','repeat','f1_score']\n",
    "random_forest_list = []\n",
    "\n",
    "for estimator in range(10, 201, 10):\n",
    "    for repeat in range(1, 5):\n",
    "        features_upsampled = pd.concat([features_zeros] + [features_ones] * repeat)\n",
    "        target_upsampled = pd.concat([target_zeros] + [target_ones] * repeat)\n",
    "        features_upsampled, target_upsampled = shuffle(features_upsampled,\n",
    "                                                       target_upsampled, \n",
    "                                                       random_state=42)\n",
    "        model_rf = RandomForestClassifier(n_estimators=estimator, random_state=42)\n",
    "        model_rf.fit(features_upsampled, target_upsampled)\n",
    "        predicted_valid = model_rf.predict(features_valid)\n",
    "        random_forest_list.append([estimator,\n",
    "                                   repeat,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "random_forest = pd.DataFrame(random_forest_list, columns=random_forest_cols)\n",
    "\n",
    "max_f1_score_row = random_forest.loc[random_forest['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "4ebf418c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimator    130.000000\n",
       "fraction       0.450000\n",
       "f1_score       0.594595\n",
       "Name: 249, dtype: float64"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Downsampling \n",
    "\n",
    "random_forest_cols = ['estimator','fraction','f1_score']\n",
    "random_forest_list = []\n",
    "\n",
    "for estimator in range(10, 201, 10):\n",
    "    for fraction in  np.arange(0, 1, 0.05):\n",
    "        features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=42)] + [features_ones])\n",
    "        target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=42)] + [target_ones])\n",
    "        features_downsampled, target_downsampled = shuffle(features_downsampled, \n",
    "                                                           target_downsampled, \n",
    "                                                           random_state=42)\n",
    "        model_rf = RandomForestClassifier(n_estimators=estimator, random_state=42)\n",
    "        model_rf.fit(features_downsampled, target_downsampled)\n",
    "        predicted_valid = model_rf.predict(features_valid)\n",
    "        random_forest_list.append([estimator,\n",
    "                                   fraction,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "random_forest = pd.DataFrame(random_forest_list, columns=random_forest_cols)\n",
    "\n",
    "max_f1_score_row = random_forest.loc[random_forest['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "625dbaba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "estimator    150.000000\n",
       "threshold      0.400000\n",
       "f1_score       0.589928\n",
       "Name: 144, dtype: float64"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Threshold Adjustment\n",
    "\n",
    "random_forest_cols = ['estimator','threshold','f1_score']\n",
    "random_forest_list = []\n",
    "\n",
    "for estimator in range(10, 201, 10):\n",
    "    for threshold in  np.arange(0, 1, 0.1):\n",
    "        model_rf = RandomForestClassifier(n_estimators=estimator, random_state=42)\n",
    "        model_rf.fit(features_train, target_train)\n",
    "        probabilities_valid = model_rf.predict_proba(features_valid)\n",
    "        probabilities_one_valid = probabilities_valid[:, 1]\n",
    "        predicted_valid = probabilities_one_valid > threshold\n",
    "        random_forest_list.append([estimator,\n",
    "                                   threshold,\n",
    "                                   f1_score(target_valid, predicted_valid)\n",
    "                                  ])\n",
    "    \n",
    "random_forest = pd.DataFrame(random_forest_list, columns=random_forest_cols)\n",
    "\n",
    "max_f1_score_row = random_forest.loc[random_forest['f1_score'].idxmax()]\n",
    "max_f1_score_row"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57239622",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "\n",
    "<h2> Enhanced Student's Comment on Random Forest Hyperparameter Tuning</h2>\n",
    "\n",
    "The code is designed for an exhaustive hyperparameter tuning of a random forest model, with the aim to optimize the F1 score. It operates on a nested loop structure, carefully iterating over a diverse range of hyperparameters, including estimator count, class_weight, fraction, and threshold.\n",
    "\n",
    "**Process Overview:**\n",
    "\n",
    "1. **Downsampling and Dataset Preparation:**  \n",
    "   Each iteration begins with the creation of a downsampled dataset, balancing the majority and minority class samples. This is crucial for addressing class imbalance and enhancing model performance.\n",
    "\n",
    "2. **Model Configuration and Training:**  \n",
    "   The random forest classifier is configured with a range of n_estimators (from 10 to 200 in increments of 10) and a class_weight parameter (either 'balanced' or None). The model is then trained on this tailored dataset.\n",
    "\n",
    "3. **Probability Assessment and Thresholding:**  \n",
    "   For validation, the model predicts probabilities for the dataset, with a subsequent threshold application to differentiate between positive and negative class predictions.\n",
    "\n",
    "4. **Performance Evaluation:**  \n",
    "   The model's effectiveness is quantified using the F1 score, derived by comparing the predictions against the actual labels in the validation dataset.\n",
    "\n",
    "5. **Logging and Analysis:**  \n",
    "   Detailed logging of hyperparameters and corresponding F1 scores is performed for each iteration. This data is systematically compiled for comprehensive analysis.\n",
    "\n",
    "6. **Identification of Optimal Configuration:**  \n",
    "   Upon completing the hyperparameter sweep, the configuration yielding the highest F1 score is pinpointed. This optimal set of hyperparameters represents the most effective model setup for our specific classification task.\n",
    "\n",
    "**Challenges Noted:**\n",
    "\n",
    "- The extensive nature of this hyperparameter tuning process results in prolonged execution times, indicating a trade-off between thoroughness and computational efficiency.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "This thorough approach, while time-intensive, is critical for identifying the most effective hyperparameter configuration for the random forest model, especially in contexts marked by class imbalances. The insights gained are invaluable for refining the model's predictive accuracy and overall efficacy.\n",
    "\n",
    "</div>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3022142b",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "Excellent, random forest model was also explored with different hyperparameters and balancing techniques\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "e01c8964",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.6204287515762925"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Improve the quality of the model. Make sure you use at least two approaches to fixing class imbalance. \n",
    "# Use the training set to pick the best parameters. Train different models on training and validation sets. \n",
    "# Find the best one. Briefly describe your findings.\n",
    "\n",
    "fraction = 0.85\n",
    "threshold = 0.4\n",
    "\n",
    "features_downsampled = pd.concat([features_zeros.sample(frac=fraction, random_state=42)] + [features_ones])\n",
    "target_downsampled = pd.concat([target_zeros.sample(frac=fraction, random_state=42)] + [target_ones])\n",
    "features_downsampled, target_downsampled = shuffle(features_downsampled, \n",
    "                                                                   target_downsampled, \n",
    "                                                                   random_state=42)\n",
    "model_rf = RandomForestClassifier(n_estimators=160, class_weight='balanced', random_state=42)\n",
    "model_rf.fit(features_downsampled, target_downsampled)\n",
    "probabilities_test = model_rf.predict_proba(features_test)\n",
    "if probabilities_test.shape[1] == 1:\n",
    "    probabilities_one_test = probabilities_test.ravel()\n",
    "else:\n",
    "    probabilities_one_test = probabilities_test[:, 1]\n",
    "predicted_test = probabilities_one_test > threshold\n",
    "\n",
    "f1_score(target_test, predicted_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "f605b7b0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x432 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "precision, recall, thresholds = precision_recall_curve(target_test, probabilities_test[:, 1])\n",
    "\n",
    "plt.figure(figsize=(6, 6))\n",
    "plt.step(recall, precision, where='post')\n",
    "plt.xlabel('Recall')\n",
    "plt.ylabel('Precision')\n",
    "plt.ylim([0.0, 1.05])\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.title('Precision-Recall Curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "932464e5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fpr, tpr, thresholds = roc_curve(target_test, probabilities_one_test)\n",
    "\n",
    "plt.figure()\n",
    "plt.plot(fpr, tpr)\n",
    "plt.plot([0, 1], [0, 1], linestyle='--')\n",
    "plt.xlim([0.0, 1.0])\n",
    "plt.ylim([0.0, 1.0])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC curve')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "2378595c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8626122055991705\n"
     ]
    }
   ],
   "source": [
    "auc_roc = roc_auc_score(target_test, probabilities_one_test)\n",
    "\n",
    "print(auc_roc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "319f9ff4",
   "metadata": {},
   "source": [
    "<div style=\"background-color: #ADD8E6; padding: 20px; border-radius: 10px; box-shadow: 2px 2px 10px grey;\">\n",
    "\n",
    "<h2> Enhanced Student's Comment on Random Forest Hyperparameter Tuning</h2>\n",
    "\n",
    "The code is designed for an exhaustive hyperparameter tuning of a random forest model, with the aim to optimize the F1 score. It operates on a nested loop structure, carefully iterating over a diverse range of hyperparameters, including estimator count, class_weight, fraction, and threshold.\n",
    "\n",
    "**Process Overview:**\n",
    "\n",
    "1. **Downsampling and Dataset Preparation:**  \n",
    "   Each iteration begins with the creation of a downsampled dataset, balancing the majority and minority class samples. This is crucial for addressing class imbalance and enhancing model performance.\n",
    "\n",
    "2. **Model Configuration and Training:**  \n",
    "   The random forest classifier is configured with a range of n_estimators (from 10 to 200 in increments of 10) and a class_weight parameter (either 'balanced' or None). The model is then trained on this tailored dataset.\n",
    "\n",
    "3. **Probability Assessment and Thresholding:**  \n",
    "   For validation, the model predicts probabilities for the dataset, with a subsequent threshold application to differentiate between positive and negative class predictions.\n",
    "\n",
    "4. **Performance Evaluation:**  \n",
    "   The model's effectiveness is quantified using the F1 score, derived by comparing the predictions against the actual labels in the validation dataset.\n",
    "\n",
    "5. **Logging and Analysis:**  \n",
    "   Detailed logging of hyperparameters and corresponding F1 scores is performed for each iteration. This data is systematically compiled for comprehensive analysis.\n",
    "\n",
    "6. **Identification of Optimal Configuration:**  \n",
    "   Upon completing the hyperparameter sweep, the configuration yielding the highest F1 score is pinpointed. This optimal set of hyperparameters represents the most effective model setup for our specific classification task.\n",
    "\n",
    "**Challenges Noted:**\n",
    "\n",
    "- The extensive nature of this hyperparameter tuning process results in prolonged execution times, indicating a trade-off between thoroughness and computational efficiency.\n",
    "\n",
    "**Conclusion:**\n",
    "\n",
    "This thorough approach, while time-intensive, is critical for identifying the most effective hyperparameter configuration for the random forest model, especially in contexts marked by class imbalances. The insights gained are invaluable for refining the model's predictive accuracy and overall efficacy.\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8b2af1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-success\">\n",
    "<b>Reviewer's comment</b>\n",
    "\n",
    "The final model was evaluated on the test set, and it passes the F1 score threshold. Well done!\n",
    "    \n",
    "Very nice analysis of the results in the conclusion!\n",
    "\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "630f7050",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.5"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
